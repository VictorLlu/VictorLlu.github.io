<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Jiachen Lu </title> <meta name="author" content="Jiachen Lu"> <meta name="description" content="Ph.D. Student at EPFL focusing on Wireless Sensing, Autonomous Driving, and 3D Vision. "> <meta name="keywords" content="Wireless Sensing, Autonomous Driving, 3D Vision, EPFL"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/epfl-logo.svg?v=0e55fc55c75dd3dda68ad4f5b803b892"> <link rel="stylesheet" href="/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://victorllu.github.io//"> <script src="/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Jiachen Lu </h1> <p class="desc"><a href="https://www.epfl.ch/en/" rel="external nofollow noopener" target="_blank">EPFL (Swiss Federal Technology Institute of Lausanne) <img class="emoji" title=":switzerland:" alt=":switzerland:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f1e8-1f1ed.png" height="20" width="20"></a>. victor(dot)lu(dot)9901(at)gmail(dot)com</p> </header> <article> <div class="profile float-right"> <figure> <picture> <img src="/assets/img/JiachenLu_ICCV.jpg?v=ec828939e348ca2e25649436beb4b158" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="JiachenLu_ICCV.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="clearfix"> <p>I am a Computer Science Ph.D. student in the <a href="https://www.epfl.ch/education/phd/edic-computer-and-communication-sciences/" rel="external nofollow noopener" target="_blank">EDIC</a> fellowship program at <strong>EPFL</strong>, where I am fortunately advised by <a href="https://people.epfl.ch/haitham.alhassanieh?lang=en" rel="external nofollow noopener" target="_blank">Haitham Hassanieh</a> in the <a href="https://sens.epfl.ch/" rel="external nofollow noopener" target="_blank">SENS (Laboratory of Sensing and Networking Systems)</a> group. My research sits at the intersection of <strong>wireless sensing</strong>, <strong>autonomous driving</strong>, and <strong>3D vision</strong>.</p> <p>Prior to joining EPFL, I earned my Master’s degree from Fudan University and my Bachelor’s degree from Shanghai Jiao Tong University (SJTU). During my time in Shanghai, my work spanned the full spectrum of computer vision, from <strong>large multi-modality models</strong>, <strong>3D/2D generative models</strong>, <strong>3D perception</strong> to the <strong>Transformer theory</strong>.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Feb 20, 2026</th> <td> My work on vision + wireless imaging <a href="https://openreview.net/revisions?id=c20LZHws55" rel="external nofollow noopener" target="_blank">Seeing through boxes: Non-Line-of-Sight 3D Reconstruction from Radar Signals</a> is accepted by <a href="https://cvpr.thecvf.com/" rel="external nofollow noopener" target="_blank">CVPR 2026</a>! <img class="emoji" title=":star_struck:" alt=":star_struck:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f929.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 18, 2025</th> <td> My work on wireless imaging <a href="https://openreview.net/pdf?id=z3PMVmzoya" rel="external nofollow noopener" target="_blank">GeRaF: Neural Geometry Reconstruction from Radio Frequency Signals</a> is accepted as <strong>spotlight</strong> by <a href="https://neurips.cc/" rel="external nofollow noopener" target="_blank">NeurIPS 2025</a>! <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 10, 2025</th> <td> My work on HDMap <a href="https://ieeexplore.ieee.org/document/11175545" rel="external nofollow noopener" target="_blank">Translating Images to Road Network: A Sequence-to-Sequence Perspective</a> is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" rel="external nofollow noopener" target="_blank">TPAMI</a> ! <img class="emoji" title=":car:" alt=":car:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f697.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 01, 2025</th> <td> I am excited to share that I have joined <strong>EPFL</strong> as a Computer Science Ph.D. student! I will be part of the <a href="https://www.epfl.ch/education/phd/edic-computer-and-communication-sciences/" rel="external nofollow noopener" target="_blank">EDIC</a> fellowship program and a member of the <a href="https://sens.epfl.ch/" rel="external nofollow noopener" target="_blank">SENS Lab</a>. Looking forward to working on wireless sensing and 3D vision in Lausanne! <img class="emoji" title=":switzerland:" alt=":switzerland:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f1e8-1f1ed.png" height="20" width="20"> </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/geraf_fig.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="geraf_fig.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lu2025geraf" class="col-sm-8"> <div class="title">GeRaF: Neural Geometry Reconstruction from Radio Frequency Signals</div> <div class="author"> <em>Jiachen Lu</em>, Hailan Shanbhag, and Haitham Al Hassanieh </div> <div class="periodical"> <em>In Conference on Neural Information Processing Systems (NeurIPS)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Spotlight</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openreview.net/pdf?id=z3PMVmzoya" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/geraf.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/assets/pdf/geraf_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=OECsdBsAAAAJ&amp;citation_for_view=OECsdBsAAAAJ:kNdYIx-mwKoC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-1-4285F4?logo=googlescholar&amp;labelColor=beige" alt="1 Google Scholar citations"> </a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Spotlight Presentation</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">lu2025geraf</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{GeRaF: Neural Geometry Reconstruction from Radio Frequency Signals}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lu, Jiachen and Shanbhag, Hailan and Al Hassanieh, Haitham}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Conference on Neural Information Processing Systems (NeurIPS)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/roadnet_fig.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="roadnet_fig.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lu2025translating" class="col-sm-8"> <div class="title">Translating Images to Road Network: A Sequence-to-Sequence Perspective</div> <div class="author"> <em>Jiachen Lu</em>, Ming Nie, Bozhou Zhang, Renyuan Peng, Xinyue Cai, Hang Xu, Feng Wen, Wei Zhang, and Li Zhang </div> <div class="periodical"> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/TPAMI.2025.3612940" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://arxiv.org/abs/2402.08207" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/11175545" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/fudan-zvg/RoadNet" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=OECsdBsAAAAJ&amp;citation_for_view=OECsdBsAAAAJ:MXK_kJrjxJIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-1-4285F4?logo=googlescholar&amp;labelColor=beige" alt="1 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">lu2025translating</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Translating Images to Road Network: A Sequence-to-Sequence Perspective}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lu, Jiachen and Nie, Ming and Zhang, Bozhou and Peng, Renyuan and Cai, Xinyue and Xu, Hang and Wen, Feng and Zhang, Wei and Zhang, Li}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TPAMI.2025.3612940}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/wovogen_fig.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="wovogen_fig.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lu2024wovogen" class="col-sm-8"> <div class="title">Wovogen: World volume-aware diffusion for controllable multi-camera driving scene generation</div> <div class="author"> <em>Jiachen Lu</em>, Ze Huang, Zeyu Yang, Jiahui Zhang, and Li Zhang </div> <div class="periodical"> <em>In European Conference on Computer Vision (ECCV)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2312.02934" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/chapter/10.1007/978-3-031-72989-8_19" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/wovogen.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/fudan-zvg/WoVoGen" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/wovogen_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=OECsdBsAAAAJ&amp;citation_for_view=OECsdBsAAAAJ:ufrVoPGSRksC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-87-4285F4?logo=googlescholar&amp;labelColor=beige" alt="87 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">lu2024wovogen</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Wovogen: World volume-aware diffusion for controllable multi-camera driving scene generation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lu, Jiachen and Huang, Ze and Yang, Zeyu and Zhang, Jiahui and Zhang, Li}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Conference on Computer Vision (ECCV)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{329--345}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/rntr_fig.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="rntr_fig.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lu2023translating" class="col-sm-8"> <div class="title">Translating images to road network: A non-autoregressive sequence-to-sequence approach</div> <div class="author"> <em>Jiachen Lu</em>, Renyuan Peng, Xinyue Cai, Hang Xu, Hongyang Li, Feng Wen, Wei Zhang, and Li Zhang </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Oral</a> <a href="http://arxiv.org/abs/2402.08207" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Translating_Images_to_Road_Network_A_Non-Autoregressive_Sequence-to-Sequence_Approach_ICCV_2023_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/rntr.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/fudan-zvg/RoadNet" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/rntr_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=OECsdBsAAAAJ&amp;citation_for_view=OECsdBsAAAAJ:0EnyYjriUFMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-16-4285F4?logo=googlescholar&amp;labelColor=beige" alt="16 Google Scholar citations"> </a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Oral Presentation</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">lu2023translating</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Translating images to road network: A non-autoregressive sequence-to-sequence approach}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lu, Jiachen and Peng, Renyuan and Cai, Xinyue and Xu, Hang and Li, Hongyang and Wen, Feng and Zhang, Wei and Zhang, Li}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{23--33}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/ego3rt_fig.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ego3rt_fig.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lu2022learning" class="col-sm-8"> <div class="title">Learning ego 3d representation as ray tracing</div> <div class="author"> <em>Jiachen Lu</em>, Zheyuan Zhou, Xiatian Zhu, Hang Xu, and Li Zhang </div> <div class="periodical"> <em>In European conference on computer vision (ECCV)</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2206.04042" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/chapter/10.1007/978-3-031-19809-0_8" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/ego3rt.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://fudan-zvg.github.io/Ego3RT/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/ego3rt_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=OECsdBsAAAAJ&amp;citation_for_view=OECsdBsAAAAJ:Se3iqnhoufwC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-70-4285F4?logo=googlescholar&amp;labelColor=beige" alt="70 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">lu2022learning</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning ego 3d representation as ray tracing}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lu, Jiachen and Zhou, Zheyuan and Zhu, Xiatian and Xu, Hang and Zhang, Li}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European conference on computer vision (ECCV)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{129--144}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/soft_fig.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="soft_fig.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lu2021soft" class="col-sm-8"> <div class="title">Soft: Softmax-free transformer with linear complexity</div> <div class="author"> <em>Jiachen Lu</em>, Jinghan Yao, Junge Zhang, Xiatian Zhu, Hang Xu, Weiguo Gao, Chunjing Xu, Tao Xiang, and Li Zhang </div> <div class="periodical"> <em>In Conference on Neural Information Processing Systems (NeurIPS)</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Spotlight</a> <a href="http://arxiv.org/abs/2110.11945" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2021/file/b1d10e7bafa4421218a51b1e1f1b0ba2-Paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/soft.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://fudan-zvg.github.io/SOFT" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=OECsdBsAAAAJ&amp;citation_for_view=OECsdBsAAAAJ:roLk4NBRz8UC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-260-4285F4?logo=googlescholar&amp;labelColor=beige" alt="260 Google Scholar citations"> </a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Spotlight Presentation</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">lu2021soft</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Soft: Softmax-free transformer with linear complexity}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lu, Jiachen and Yao, Jinghan and Zhang, Junge and Zhu, Xiatian and Xu, Hang and Gao, Weiguo and Xu, Chunjing and Xiang, Tao and Zhang, Li}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Conference on Neural Information Processing Systems (NeurIPS)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/setr_fig.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="setr_fig.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="zheng2021rethinking" class="col-sm-8"> <div class="title">Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers</div> <div class="author"> Sixiao Zheng, <em>Jiachen Lu</em>, Hengshuang Zhao, Xiatian Zhu, Zekun Luo, Yabiao Wang, Yanwei Fu, Jianfeng Feng, Tao Xiang, Philip HS Torr, and others </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR)</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a href="http://arxiv.org/abs/2207.09339" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Zheng_Rethinking_Semantic_Segmentation_From_a_Sequence-to-Sequence_Perspective_With_Transformers_CVPR_2021_paper.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/setr.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/fudan-zvg/SETR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=OECsdBsAAAAJ&amp;citation_for_view=OECsdBsAAAAJ:u-x6o8ySG0sC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-4821-4285F4?logo=googlescholar&amp;labelColor=beige" alt="4821 Google Scholar citations"> </a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zheng2021rethinking</span><span class="p">,</span>
  <span class="na">selected</span> <span class="p">=</span> <span class="nv">true</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zheng, Sixiao and Lu, Jiachen and Zhao, Hengshuang and Zhu, Xiatian and Luo, Zekun and Wang, Yabiao and Fu, Yanwei and Feng, Jianfeng and Xiang, Tao and Torr, Philip HS and others}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{6881--6890}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="/assets/pdf/CV_JiachenLu_epfl.pdf" title="Cv pdf"><i class="ai ai-cv"></i></a> <a href="mailto:victor.lu.9901@gmail.com" title="Email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=OECsdBsAAAAJ" title="Scholar userid" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> </div> <div class="contact-note">The best way to reach me is via email. </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Jiachen Lu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>